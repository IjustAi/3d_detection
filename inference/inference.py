import torch
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from torchvision import transforms
import os

from model import ViT3DDetector

class InferenceEngine:
    def __init__(self, cfg, model_path):
        self.cfg = cfg
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        print(f"ğŸ” Initializing Inference Engine")
        print(f"Device: {self.device}")
        
        # åŠ è½½æ¨¡å‹
        self.model = ViT3DDetector(
            backbone=cfg.BACKBONE,
            hidden_dim=cfg.HIDDEN_DIM,
            num_queries=cfg.NUM_QUERIES,
            dropout=0.1
        ).to(self.device)
        
        self.load_model(model_path)
        self.model.eval()
        
        print(f"âœ“ Model loaded and ready")
        
        # Transform
        self.transform = transforms.Compose([
            transforms.Resize(cfg.IMAGE_SIZE),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])
        ])
        
        # Visualization colors
        self.colors = {
            '2d_box': (0, 255, 0),      # ç»¿è‰²
            '3d_box': (255, 0, 0),      # çº¢è‰²
            '3d_front': (0, 0, 255)     # è“è‰²ï¼ˆå‰é¢ï¼‰
        }
    
    def load_model(self, model_path):
        """åŠ è½½æ¨¡å‹"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model not found: {model_path}")
        
        checkpoint = torch.load(model_path, map_location=self.device)
        
        if 'model_state_dict' in checkpoint:
            self.model.load_state_dict(checkpoint['model_state_dict'])
            epoch = checkpoint.get('epoch', 'unknown')
            loss = checkpoint.get('best_loss', 0)
            print(f"âœ“ Loaded from epoch {epoch}, loss: {loss:.4f}")
        else:
            self.model.load_state_dict(checkpoint)
        
        print(f"âœ“ Model: {model_path}")
    
    def run_inference(self, image_path, box2d_query, intrinsic_params, conf_threshold=0.3):
        """è¿è¡Œæ¨ç†"""
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        
        # é¢„å¤„ç†
        image_tensor = self.transform(image).unsqueeze(0).to(self.device)
        box2d_tensor = torch.FloatTensor([box2d_query]).unsqueeze(0).to(self.device)
        intrinsic_tensor = torch.FloatTensor(intrinsic_params).unsqueeze(0).to(self.device)
        
        # æ¨ç†
        with torch.no_grad():
            pred_boxes, pred_conf = self.model(image_tensor, box2d_tensor, intrinsic_tensor)
        
        # æå–ç»“æœ
        pred_box3d = pred_boxes[0, 0].cpu().numpy()
        confidence = pred_conf[0, 0, 0].cpu().item()
        
        # æ‰“å°ç»“æœ
        print(f"\\nğŸ“Š Prediction:")
        print(f"  Center (x,y,z): ({pred_box3d[0]:.2f}, {pred_box3d[1]:.2f}, {pred_box3d[2]:.2f}) m")
        print(f"  Size (l,h,w): ({pred_box3d[3]:.2f}, {pred_box3d[4]:.2f}, {pred_box3d[5]:.2f}) m")
        print(f"  Rotation: {np.degrees(pred_box3d[6]):.1f}Â°")
        print(f"  Confidence: {confidence:.3f}")
        
        # å¯è§†åŒ–
        result_image = self.create_visualization(
            image_path,
            box2d_query,
            pred_box3d,
            intrinsic_params,
            confidence
        )
        
        return result_image, pred_box3d, confidence
    
    def project_3d_to_2d(self, box3d, intrinsic):
        """å°†3Dæ¡†æŠ•å½±åˆ°2Då¹³é¢"""
        cx, cy, cz, sx, sy, sz, alpha = box3d
        fx, fy, cx_img, cy_img = intrinsic
        
        # 8ä¸ªè§’ç‚¹ï¼ˆæœ¬åœ°åæ ‡ç³»ï¼Œåº•é¢ä¸­å¿ƒä¸ºåŸç‚¹ï¼‰
        x_corners = np.array([1, 1, -1, -1, 1, 1, -1, -1]) * sx / 2
        y_corners = np.array([0, 0, 0, 0, -1, -1, -1, -1]) * sy  # y=0æ˜¯åº•é¢
        z_corners = np.array([1, -1, -1, 1, 1, -1, -1, 1]) * sz / 2
        
        corners_3d = np.vstack([x_corners, y_corners, z_corners]).T  # (8, 3)
        
        # æ—‹è½¬çŸ©é˜µï¼ˆç»•Yè½´ï¼‰
        rot_matrix = np.array([
            [np.cos(alpha), 0, np.sin(alpha)],
            [0, 1, 0],
            [-np.sin(alpha), 0, np.cos(alpha)]
        ])
        
        # åº”ç”¨æ—‹è½¬å’Œå¹³ç§»
        corners_3d_world = corners_3d @ rot_matrix.T  # æ—‹è½¬
        corners_3d_world[:, 0] += cx  # å¹³ç§»x
        corners_3d_world[:, 1] += cy  # å¹³ç§»y
        corners_3d_world[:, 2] += cz  # å¹³ç§»z
        
        # æŠ•å½±åˆ°2D
        corners_2d = []
        for corner in corners_3d_world:
            if corner[2] > 0:  # ç¡®ä¿åœ¨ç›¸æœºå‰æ–¹
                x = (fx * corner[0]) / corner[2] + cx_img
                y = (fy * corner[1]) / corner[2] + cy_img
                corners_2d.append([x, y])
            else:
                return None  # åœ¨ç›¸æœºåæ–¹
        
        return np.array(corners_2d)
    
    def draw_2d_box(self, draw, box2d, color=(0, 255, 0), thickness=3):
        """ç»˜åˆ¶2Dè¾¹ç•Œæ¡†"""
        min_x, min_y, max_x, max_y = box2d
        draw.rectangle([min_x, min_y, max_x, max_y], outline=color, width=thickness)
    
    def draw_3d_box(self, draw, corners_2d, color=(255, 0, 0), thickness=2):
        """ç»˜åˆ¶3Dæ¡†æŠ•å½±"""
        if corners_2d is None:
            return
        
        # å®šä¹‰è¾¹
        edges = [
            (0, 1), (1, 2), (2, 3), (3, 0),  # åº•é¢
            (4, 5), (5, 6), (6, 7), (7, 4),  # é¡¶é¢
            (0, 4), (1, 5), (2, 6), (3, 7)   # å‚ç›´è¾¹
        ]
        
        # ç»˜åˆ¶æ‰€æœ‰è¾¹
        for edge in edges:
            start_idx, end_idx = edge
            start_point = tuple(corners_2d[start_idx].astype(int))
            end_point = tuple(corners_2d[end_idx].astype(int))
            draw.line([start_point, end_point], fill=color, width=thickness)
        
        # é«˜äº®å‰é¢ï¼ˆè“è‰²ï¼‰
        front_edges = [(0, 1), (1, 5), (5, 4), (4, 0)]
        for edge in front_edges:
            start_idx, end_idx = edge
            start_point = tuple(corners_2d[start_idx].astype(int))
            end_point = tuple(corners_2d[end_idx].astype(int))
            draw.line([start_point, end_point], fill=self.colors['3d_front'], width=thickness+1)
    
    def create_visualization(self, image_path, box2d_query, pred_box3d, intrinsic, confidence):
        """åˆ›å»ºå®Œæ•´çš„å¯è§†åŒ–"""
        # åŠ è½½åŸå§‹å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        draw = ImageDraw.Draw(image, 'RGBA')
        
        # 1. ç»˜åˆ¶2DæŸ¥è¯¢æ¡†ï¼ˆç»¿è‰²ï¼‰
        self.draw_2d_box(draw, box2d_query, color=self.colors['2d_box'], thickness=3)
        
        # 2. æŠ•å½±å¹¶ç»˜åˆ¶3Dæ¡†ï¼ˆçº¢è‰²+è“è‰²å‰é¢ï¼‰
        corners_2d = self.project_3d_to_2d(pred_box3d, intrinsic)
        if corners_2d is not None:
            self.draw_3d_box(draw, corners_2d, color=self.colors['3d_box'], thickness=2)
        
        # 3. æ·»åŠ æ–‡æœ¬ä¿¡æ¯
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 16)
        except:
            font = ImageFont.load_default()
        
        cx, cy, cz, sx, sy, sz, alpha = pred_box3d
        info_text = [
            f"3D Center: ({cx:.2f}, {cy:.2f}, {cz:.2f}) m",
            f"Dimensions: ({sx:.2f}, {sy:.2f}, {sz:.2f}) m",
            f"Rotation: {np.degrees(alpha):.1f}Â°",
            f"Confidence: {confidence:.3f}"
        ]
        
        # æ–‡æœ¬èƒŒæ™¯
        text_bg_height = len(info_text) * 25 + 20
        draw.rectangle([10, 10, 420, text_bg_height], fill=(0, 0, 0, 180))
        
        # ç»˜åˆ¶æ–‡æœ¬
        y_offset = 15
        for text in info_text:
            draw.text((15, y_offset), text, fill=(255, 255, 255), font=font)
            y_offset += 25
        
        # 4. æ·»åŠ å›¾ä¾‹
        legend_y = text_bg_height + 10
        draw.rectangle([10, legend_y, 300, legend_y + 80], fill=(0, 0, 0, 180))
        
        legend_items = [
            ("Green: 2D Query", self.colors['2d_box']),
            ("Red: 3D Box", self.colors['3d_box']),
            ("Blue: Front Face", self.colors['3d_front'])
        ]
        
        y_offset = legend_y + 10
        for text, color in legend_items:
            draw.rectangle([15, y_offset, 35, y_offset + 15], fill=color)
            draw.text((45, y_offset), text, fill=(255, 255, 255), font=font)
            y_offset += 25
        
        return image
    
    def batch_inference(self, image_paths, box2d_queries, intrinsic_params_list, output_dir):
        """æ‰¹é‡æ¨ç†"""
        os.makedirs(output_dir, exist_ok=True)
        
        results = []
        print(f"\\n{'='*60}")
        print(f"Batch Inference: {len(image_paths)} images")
        print(f"{'='*60}")
        
        for idx, (img_path, box2d, intrinsic) in enumerate(zip(image_paths, box2d_queries, intrinsic_params_list)):
            print(f"\\n[{idx+1}/{len(image_paths)}] {os.path.basename(img_path)}")
            
            result_image, pred_box3d, confidence = self.run_inference(img_path, box2d, intrinsic)
            
            # ä¿å­˜
            output_path = os.path.join(output_dir, f'result_{idx:04d}.jpg')
            result_image.save(output_path)
            print(f"âœ“ Saved: {output_path}")
            
            results.append({
                'image': img_path,
                'pred_box3d': pred_box3d.tolist(),
                'confidence': confidence,
                'output': output_path
            })
        
        # ä¿å­˜JSON
        import json
        json_path = os.path.join(output_dir, 'predictions.json')
        with open(json_path, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\\n{'='*60}")
        print(f"âœ… Batch complete! Results: {output_dir}")
        print(f"{'='*60}")
        
        return results